% !TeX spellcheck = en_US
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex

\chapter{Related Work}
The MORE algorithm can be used as a model-free policy
search algorithm with an information theoretic approach for
updating the policy.
Information-theoretic policy algorithms use
the Kullback-Leibler Divergence in a constrained optimization problem
to bound the distance of the old policy to the new one.
Whereas MORE uses a surrogate model to compute the new search distribution
in closed form other methods like
the relative entropy policy search algorithm (REPS)
proposed in \citet{peters2010relative} use a
sample-based approximation for the KL-divergence. While in
\citet{peters2010relative} a step-based policy search
algorithm is proposed the episode-based
version of REPS is presented in \citet{kupcsik2013data} which is equivalent
to stochastic search.
Using Taylor approximations of the KL-divergence leads to the
natural evolutionary strategies (NES)
presented in \citet{wierstra2014natural}. 
NES uses the concept of the natural gradient, where the update is performed
according to the standard gradient while simultaneously satisfying the
KL-bound between subsequent search distributions.

The Covariance Matrix Adaptation-Evolutionary Strategy (CMA-ES)
\citep{hansen2016cma}
is a widely used stochastic search algorithm. It is based on
well-defined heuristics to update the search distribution. In our experiments
we try to beat the benchmark for sample efficiency set by this algorithm.

A contextual version of MORE has been
explored in \citet{tangkaratt2017policy}, where
variables that do not change for a given task
but vary from one task to another
give the notion of context. Enabling
learning from high-dimensional
context variables like camera images.

Model-based methods for approximating the objective function
with a local surrogate have been used in
derivative free optimization \citet{nocedal2006numerical}.
Also, local surrogate models have been used in trust region
methods like \citet{powell2009bobyqa}.
These methods maintain a point estimate
and a trust region around this point instead
of a search distribution. The point estimate is updated by optimizing
the surrogate and staying in the trust region.

Recursive estimation with methods like
the Kalman Filter is extensively used in robotics \citep{chen2011kalman},
mainly to estimate the state and environment of the robot
from noisy sensor measurements.
%The Kalman Filter has also been used in recent probabilistic deep
%learning for deep time series modeling \citet{NIPS2016_697e382c}.

% finish on next Iteration
% - write about MORE original approach, dimensionality reduction

% - look for related work of applying kalman filter to various problems
  % in ML
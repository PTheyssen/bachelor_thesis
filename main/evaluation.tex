% !TeX spellcheck = en_US
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex

\chapter{Evaluation}
In this chapter we first describe the setup for our experiments.
%and list all hyperparameters for our algorithm.
Then we introduce the Rosenbrock function, the planar
reaching task and the ball-in-a-cup task. For each problem
we present the best results
we could find with our algorithm and compare it to the batch solution
and the original MORE approach.
% Afterwards we review various results from our
% hyperparameter search.

% things to benchmark
% - loss
% - sample efficiency
% - run time

\section{Setup}
All algorithms were implemented in python using
NumPy\footnote{\href{https://numpy.org/}{https://numpy.org/}}.
The optimization algorithm for MORE is Low-storage BFGS
from NLopt\footnote{\href{https://nlopt.readthedocs.io/en/latest/}
{https://nlopt.readthedocs.io/en/latest/}}.
The clusterwork2 (cw2) framework, developed at the
Autonomous Learning Robots (ALR) Lab, was used for
running experiments in a convenient way.
The experiments were conducted on a machine with two 8-core
AMD Ryzen 2700X processors clocked at 2.6 GHz and 31GB of RAM.


\section{Experiments}
The focus in our experiments is on the sample efficiency of the
MORE algorithm. While the original MORE algorithm achieves
state-of-the-art results in terms of optimization accuracy
the surrogate model estimation is data-intensive.
Therefore the metric we focus on is sample efficiency for which we
use the heuristic
$s = 4 + \lfloor 3 \log(n) \rfloor$ of the CMA-ES
algorithm \citep{hansen2016cma} as a benchmark, with $n$ being the dimension
of the problem and $s$ the number of samples drawn from the
search distribution in each iteration.

We compare our recursive least squares (RLS) approach
to the ridge regression (RR) and
the original MORE algorithm, which uses Bayesian dimensionality
reduction approach combined with linear regression (BLR).
Generally, we use the
CMA-ES heuristic to determine the number of samples.
As we are working with a stochastic search algorithm we do
10 runs with each approach and calculate the \textit{arithmetic} mean.

% TODO: skip or really use systematic data in appendix
% For an exhaustive hyperparameter search and a listing of the obtained results
% see \Cref{appendix:par_search}.

\subsection{Test Functions for Optimization}
\label{sec:test_func}
Test functions provide artificial landscapes to evaluate the
performance of optimization algorithms. They can be used to
assess robustness, convergence speed and general performance of the
algorithms \citep{molga2005test}.

The Rosenbrock function (\Cref{fig:rosenbrock}) is uni-modal and convex.
It has one global optimum which is inside a parabolic shaped flat valley.
It is usually easy to find the valley,
however finding the global optimum is particularly difficult,
which makes this function popular for testing the performance
of algorithms.
It is defined as 
\begin{equation*}
 f(x) = \sum^{n-1}_{i=1} [100(x_{i+1} - x_i^2)^2 + (1-x_i)^2].
\end{equation*}

\begin{figure}[ht!]
    \centering
    \includesvg[width=0.4\textwidth]{figures/rosenbrock_function}
    \caption{2D Rosenbrock function}
    \label{fig:rosenbrock}
\end{figure}

The function has a global minimum at zero $(f(\mathbf{x}) = 0)$.
In our experiments we initialize the mean of the search distributions
randomly. We test our algorithm on the 15 dimensional
Rosenbrock function, the results are shown in \Cref{fig:rosen_result}.
For these results RLS uses 7 samples per iteration and a pool
of size 100, whereas the ridge regression uses 12 samples per
iteration and a pool
of size 204. The BLR approach only worked with using 30 samples
per iteration and a pool of size 150. The RLS approach
outperforms the other methods in terms of total samples needed for
convergence. 
% TODO add result on rosenbrock 8 dim on the side
% TODO look for styling plots --> make them look better
\begin{figure}[ht!]
     \centering
     \input{figures/rosenbrock15dim}
     \hspace{1cm}                       
     \caption{
       This figure shows the mean of 10 runs for RLS, ridge regression (RR)
       and the original MORE algorithm, which uses
       Bayesian Linear Regression (BLR),
       on 15 dimensional Rosenbrock.
     }
     \label{fig:rosen_result}  
\end{figure}

% minipage example
%\begin{figure}
%    \centering
%    \begin{minipage}{0.45\textwidth}
%      \centering
%      \includegraphics[width=1\textwidth]{figures/5dim}
%      \hspace{1cm}                       
%      \caption{5 dimensional Rosenbrock}
%      \label{fig:5dim}
%    \end{minipage}\hfill
%    \begin{minipage}{0.45\textwidth}
%      \centering
%      \includegraphics[width=1\textwidth]{figures/15dim}
%      \hspace{1cm}                       
%      \caption{15 dimensional Rosenbrock}
%      \label{fig:15dim}
%    \end{minipage}
%  \end{figure}

\subsection{Planar Reaching Task}
Policy search methods enable us to work with parameterized policies,
therefore we can use a policy representation that is relevant
to a given task.
In robotics Dynamic Movement Primitives 
(DMPs) first introduced in \citet{ijspeert2002learning} are
commonly used for movement tasks.
Formalized as second-order dynamic systems, DMPs offer a compact
representation for movements, allowing to choose between a rhythmic
and a discrete movement. 

For our task we use a 5 link robot with DMPs as the underlying
control policy. The end-effector of the robot has
to reach a via-point $v_{100} = [1,1]$ at time step 100
and at the final time step $T = 200$ the via-point $v_{\, 200} = [5,0]$.
The reward is given by a quadratic cost term for
the two via-points, for self-collision a penalty of 100 is given.
As the the via-points are defined in end effector space the objective
function is highly non-quadratic in the parameters. Using
5 basis functions per degree of freedom for the DMPs results
in a 25 dimensional parameter vector.
In \Cref{fig:reaching_result} we see the average reward and the resulting
movement from one RLS run. The ridge regression had more problems
with avoiding a self-collision than the other two approaches.
The RLS algorithm performs slightly better than BLR and RR, but overall
these the improvement seems not very significant as we have to take the
underlying stochastic nature into account. But nonetheless we could show that
MORE with recursive surrogate-modeling is able to learn the reaching task.

\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
      \centering
      \input{figures/via_results}
      \hspace{1cm}                       
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
      \centering
      \input{figures/via_movement}
      \hspace{1cm}                       
    \end{minipage}
     \caption{\small
       {\color{gray!25!black!60} Left:}
       Results on via-point reaching task
       using the recursive least squares (RLS),
       the ridge regression (RR)
       and the original approach
       (BLR).
       {\color{gray!25!black!60} Right:} Resulting movement for
       via-point reaching task of the RLS algorithm.
       The via-points are indicated by the red crosses. The
       postures of the resulting motion are shown as overlay.
       Darker postures are later in time.
     }
     \label{fig:reaching_result}      
\end{figure}

% \subsection{Mujoco Reaching Task}
% Using mujoco we use a simulated reaching task.

% \subsection{Hyper parameter Search}
% - do this better --> compare ALGO II theses
% - do great graphics, tables, figures for this
% - try doing a sweep with wandb (or manually)
% - research how to do good algorithm engineering
% make table of parameters to tune
% look for best way to show results (table with highlighted numbers)

\subsection{Ball in a Cup}
The motor skill game Ball-in-a-Cup consists
of small cup that has a string with a ball attached to it.
Initially the ball hangs down vertically in a resting position.
See \Cref{fig:cup} for a picture of the setup in the simulation
framework.
The goal is to toss the ball up and catch it inside the cup.
The reward signal is based on calculating the distance $d$ from
the center of the cup to the ball. When the ball lands directly in
the center of the cup, the distance is 0 and through the
transformation $\text{exp}(-d^2)$ it yields the highest possible
reward of 1.
We ran a simulation with the Barret WAM robot arm with three
degree of freedom (DoF) using the
MuJoCo\footnote{\href{http://www.mujoco.org/}{http://www.mujoco.org/}}
physics engine.
Our results are shown in \Cref{fig:cup}.
In our remaining time for the thesis we could only complete
5 runs for each approach as the samples have to be evaluated using the
mujoco framework which produces long runtimes. Therefore
the results should be considered preliminary.
The BLR seems to converge prematurely, though this may be due to
a suboptimal entropy constraint parameter.
Still, we can see that RLS is succesfull in learning the ball-in-a-cup task
while the ridge regression struggles with finding a good solution.
% Until the submission of this thesis we only managed to complete
% 5 runs for this experiment. 


\begin{figure}
  \centering
    \begin{minipage}{0.45\textwidth}
      \centering
      \input{figures/cup_results}
      \hspace{1cm}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
      \centering
      \includegraphics[scale=0.7]{figures/ball_in_a_cup_hack.png}
      \hspace{1cm}
    \end{minipage}
     \caption{\small
       {\color{gray!25!black!60} Left:}
       Results on ball-in-a-cup task
       using the recursive least squares (RLS),
       the ridge regression (RR)
       and the original approach (BLR), using the mean of 5 runs.
       {\color{gray!25!black!60} Right:}
       Picture of the ball-in-a-cup task in the simulation framework.
     }
     \label{fig:cup}
\end{figure}

%\subsection{Further Investigations}
%In our experiments we have to deal with unsmooth reward functions
%due to penalties. For our batch solution we normalize our data
%using the standard score, for this we use the we calculate
%the mean and variance of the current batch of rewards.
%
%
%- tried exponential moving average, the goal was
%to have the same mean as using a pool for normalization
%
%- show plots from notion
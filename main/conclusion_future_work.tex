% !TeX spellcheck = en_US
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex

\chapter{Conclusion and Future Work}


\section{Conclusion}
- managed to improve sample efficiency on simple test functions

- epsilon for kl-bound should have effect on effectiveness of RLS
  since the surrogate models become more or less locally correlated

We achieved some good results on the rosenbrock test function
considerably improving the sample efficiency. Nonetheless for
the planar reaching tasks we did not manage to achieve a
significant improvement.
Also our proposed algorithm did not work with multi modal and noisy objective functions.

- One main problem seems to be tuning the recursive estimation for one specific
task.

The data seems to be difficult to Still

- inexperience of author with kalman filter (setting up matrices, choosing good state transition model)

- use some form of dimensionality reduction as we deal with
high dimensional --> need to estimate $1 + 25 + (25 \times 26 / 2) = 351$

\section{Future Work}
- remove sample pool

- usage of state transition model (kalman filter prediction step)

- make learning more stable for reaching tasks (safe exploration)

- learning the model noise: run original MORE approach and do backpropagation with pytorch over the
weights
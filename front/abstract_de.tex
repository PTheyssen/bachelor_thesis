% !TeX spellcheck = de_DE
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex

\chapter*{Zusammenfassung}
\addcontentsline{toc}{chapter}{Zusammenfassung}
Roboter werden in den nächsten Jahrzehnten zunehmend unseren
Alltag durchdringen. Sie werden ein breites Spektrum an
Aufgaben wie Altenpflege, Such- und Rettungsaufgaben und allgemeine
Assistenz im täglichen Leben übernehmen können.
Derzeit sind die meisten Roboter darauf angewiesen von einem
erfahrenen menschlichen Bediener programmiert zu werden.
Damit Roboter Teil des täglichen Lebens werden können, müssen sie
sich in verändernden Umgegebungen zurechtfinden und sich an
neue Situationen anpassen.
Daher werden selbstlernende Roboter zunehmend an Bedeutung gewinnen.
Die Forschung zu autonom lernende Roboter ist
bereits sehr aktiv und wird weiter an Bedeutung gewinnen.
Es besteht eine enge Beziehung zwischen Reinforcement Learning und
Robotik, wobei sich beide Forschungsgebiete gegenseitig ergänzen.
Eine wichtige Herausforderung ist es dateneffiziente Methoden
für selbstlernende Roboter zu entwickeln, da Stichproben
aus realen Interaktionen sehr kostspielig sind.
Policy-Suchmethoden, ein Teilgebiet des Reinforcement Learning,
können eingesetzt werden um verschiedene Aufgaben durch Versuch und Irrtum
zu erlernen.

In dieser Arbeit versuchen wir, die Dateneffizienz eines
Policy-Suchalgorithmus zu verbessern.
Dafür benutzen wir rekursive Schätzmethoden wie den Kalman
Filter, der aus einer Bayes'schen Perspektive eingeführt wird.
Wir implementieren verschiedene Versionen von Filteralgorithmen
und vergleichen sie mit bisherigen Methoden
und testen unsere Algorithmen auf Optimierungs-Testfunktionen
und simulierten Robotik Aufgaben.


% !TeX spellcheck = en_US
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

Robots will increasingly permeate our daily lifes over the next few decades.
Fulfilling a wide range of tasks like elder care, search
and rescue and general assistance in daily life.
Today most robots rely on being
taught and programmed by a skilled human operator.
For robots to become part of daily life they need to cope
with changing environments and adjust to new situations,
therefore problem of autonomously learning robotics will become more
important. Currently robot learning is already
a very active field of research. There is a close relationship between Reinforcement learning and
robotics, where both areas of research complement each other.
A big challenge for robot learning is being sample efficiency,
because real world samples are costly to obtain.
Policy search methods, a sub-field of reinforcement learning,
can be used to learn different task only through trial and error.


In this thesis we try to improve the sample efficiency
of a policy search algorithm.
This is done using classical recursive estimation
techniques like the Kalman filter, introduced from a Bayesian perspective.
We implement different versions of Filtering algorithms and compare them with
previous methods and benchmark them on optimization test function and simple
planar reaching tasks.
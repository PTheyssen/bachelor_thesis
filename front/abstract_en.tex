% !TeX spellcheck = en_US
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

Robots will increasingly permeate our daily life over the next few decades.
Potentially fulfilling a wide range of tasks like elder care, search
and rescue and general assistance in daily life.
Today, most robots rely on being
taught and programmed by a skilled human operator.
For robots to become part of daily life, they need to cope
with changing environments and regularly adjust to new situations.
For mastering these challenges autonomously learning robots pose a
promising solutions.
Currently, robot learning is already
a very active field of research. There is a close
relationship between reinforcement learning and
robotics where both fields of research complement each other.
A big challenge for robot learning is sample efficiency
because real world samples are costly to obtain.
Policy search methods, a sub-field of reinforcement learning,
can be used to learn different tasks simply through trial and error.


In this thesis we try to improve the sample efficiency
of a policy search algorithm.
This is done using classical recursive estimation
techniques like the Kalman filter, introduced from a Bayesian perspective.
We implement different versions of filtering algorithms and compare them with
previous methods and benchmark them on optimization test functions
and various simulated robot tasks.
